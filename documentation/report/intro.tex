	A chatbot is a program that provides conversational output in response to user input.
	They have many applications such as customer support interfaces, general question answering services, translation apps and virtual assistants.
	A common goal for chatbots is to simulate a human like interaction for the user.
	To this end many researches have investigated creating chatbots with "personality" or "identity" \cite{Li2016, LINH2019, QianHZXZ17, ZhouHZZL17,NMC2017, 8614104}.
	Such chatbots could drastically improve improve the user experience of nearly all chatbot applications.
	Consider for example the marketability of a witty virtual assistant or an comforting customer service support chatbot.

	Similar to \cite{NMC2017, Li2016, 8614104}, we investigate the related problem of training a neural network to respond like a popular television character, Joey from Friends.
	While general personality qualities might have more wide spread usefulness in real life applications, the ability to mimic well-known personalities such as Joey would also have commercial applications.
	More importantly, such a task can be seen as an important first step to solving the more general problem of training a machine to behave like a human.
	Motivated by this and previous examples, in this work we investigate training two different neural network models act as chatbots with personality.
	In the following sections we will review the dataset we used, the evaluations we performed, the models we considered and then conclude with our results and final thoughts.
	
%	\texttt{We choose Joey because there are existing results in previous papers to compare to, the Friends scripts are publicly available and because we believed that his strong personality would be an easier for our models to successfully mimic.
%	Joey is often described as naive, good-matured, dimwitted, childish and promiscuous. 
%	In a a later section we will explain what dataset was use and how it was created.
%	
%	In this project we considered two neural network models: a sequence-to-sequence model and a transformer model.
%	We picked these models because of their success as general chatbots and translation bots.
%	Our tasks seems to be heavily linked to both of these.
%	Indeed, one way to attempt our tasks would be to perform a two step process which first generates a generic human like response to a statement and then translates it to sound like the normal dialogue Joey.
%	Moreover, we also picked these models because past works have had some success with directly apply them to the same problem \cite{NMC2017, Li2016, 8614104}.
%	We will discuss both models' details, successes, and weaknesses in later sections.
%	
%	To evaluate the performance of our models we considered two types of metrics: automatic metrics and human metrics.
%	The automatic metrics we considered were those which are usually used to evaluate the performance of translation bots: BLEU, ROUGE, METEOR and WER \cite{Papineni:2002:BMA:1073083.1073135, lin-2004-rouge, denkowski:lavie:meteor-wmt:2014}.
%	While there seems to be a heavy relationship between our task and that of machine translation, these metrics are known to consistently be poor measures of performance for personality chatbots \cite{Radz2017, Xing2018, LiuLSNCP16, SerbanLCP15}.
%	Despite their poor performance, these metrics are still often used as a means to understand some aspects a model's success.
%	However, our primary metric of interest is based on human feedback.
%	For a human based metric we designed a test similar to that of the popular Turing test and asked those familiar with the Joey character to answer a series of questions about responses generated by each of our models.
%	We will discuss both types of metrics in a later section.}