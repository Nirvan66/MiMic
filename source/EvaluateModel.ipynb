{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import AutomaticMetrics\n",
    "from Mimic import Preprocessor\n",
    "from Mimic import Mimic\n",
    "\n",
    "from Stupid import Stupid\n",
    "from Smart import Smart\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = Mimic.load('joeyData/joey400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990032906999293"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = 'joey'\n",
    "genericQuestions = pickle.load(\n",
    "    open('joeyData/genericQuestionsTest.pkl'.format(person), 'rb'))\n",
    "genericAnswers = pickle.load(\n",
    "    open('joeyData/genericAnswersTest.pkl'.format(person), 'rb'))\n",
    "personInput = pickle.load(\n",
    "    open('{}Data/{}InputTest.pkl'.format(person,person), 'rb'))\n",
    "personOutput = pickle.load(\n",
    "    open('{}Data/{}OutputTest.pkl'.format(person,person), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = AutomaticMetrics.AutomaticMetricTester(mic, genericQuestions, genericAnswers, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.compileScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE SCORE:  0.055334819988162046\n",
      "ROGUE 1 Recall Average:  0.2046666666666667\n",
      "ROGUE 1 Precision Average:  0.3203357753357753\n",
      "ROGUE 1 F1:  0.2228766600409069\n",
      "ROGUE 4 Recall Average:  0.05555555555555556\n",
      "ROGUE 4 Precision Average:  0.05\n",
      "ROGUE 4 F1:  0.05263157894736842\n",
      "ROGUE el Recall Average:  0.19552380952380952\n",
      "ROGUE el Precision Average:  0.3011691086691087\n",
      "ROGUE el F1:  0.2125318324547\n",
      "METEOR Precision:  0.1329268292682927\n",
      "METEOR Recall:  0.22598870056497175\n",
      "METEOR f1:  0.16739293187184456\n",
      "METEOR fmean:  0.20451192712620872\n",
      "METEOR Score:  0.08801109283539499\n",
      "WER Average Error:  0.8803042328042329\n"
     ]
    }
   ],
   "source": [
    "tester.printScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = AutomaticMetrics.AutomaticMetricTester(mic, personInput, personOutput, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.compileScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE SCORE:  0.0042827845753402125\n",
      "ROGUE 1 Recall Average:  0.15051639515455306\n",
      "ROGUE 1 Precision Average:  0.15738672351575578\n",
      "ROGUE 1 F1:  0.13614980315895647\n",
      "ROGUE 4 Recall Average:  0.0\n",
      "ROGUE 4 Precision Average:  0.0\n",
      "ROGUE 4 F1:  0.0\n",
      "ROGUE el Recall Average:  0.13010703842940685\n",
      "ROGUE el Precision Average:  0.13635068747971973\n",
      "ROGUE el F1:  0.11777733352332893\n",
      "METEOR Precision:  0.12022471910112359\n",
      "METEOR Recall:  0.12634920634920635\n",
      "METEOR f1:  0.12321090167373096\n",
      "METEOR fmean:  0.125391055736392\n",
      "METEOR Score:  0.05323287143982688\n",
      "WER Average Error:  1.1593374060150377\n"
     ]
    }
   ],
   "source": [
    "tester.printScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
