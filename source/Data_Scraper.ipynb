{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friends Data Scraper\n",
    "* Created by: Nirvan S P Theethira\n",
    "* Date: 12/01/2019\n",
    "* Purpose:  CSCI 5266 Fall Group Project: Mimic\n",
    "* This files contains the code to extract charachter dialogue data from friends scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read a csv script file\n",
    "* Reads a script and extract a particular charachters `person` response to a dialogue. The dialogue the charachter respons to is also noted down. The inputs and the outputs for a charachter are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(lines, person):\n",
    "    scene = ''\n",
    "    preChar = ''\n",
    "    preScene = ''\n",
    "    dialogue = ''\n",
    "    # dataF = {'scene':[],'person':[], 'dialogue':[]}\n",
    "    dataF = []\n",
    "    dataRaw = ''\n",
    "    prevDialogue = ''\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for line in lines:\n",
    "        line = re.sub('\\n','',line)\n",
    "        if re.search(r\"^\\[[\\w\\W]+\\]$\", re.sub('\\n','',line)):\n",
    "            scene = line\n",
    "        if re.search('^[a-zA-Z]+:',line) and len(scene)>0:\n",
    "            charachter = re.findall('^[a-zA-Z]+:',line)[0]\n",
    "            charachter = re.sub(':','',charachter).upper()\n",
    "            if preChar!=charachter and len(preChar)!=0:\n",
    "                if preChar==person:\n",
    "                    dialogue = re.sub('\\((.*?)\\)','',dialogue)\n",
    "                    dialogue = re.sub(\"[’']\",\"\",dialogue)\n",
    "                    dialogue = re.sub('^\\s+','',dialogue)\n",
    "                    dialogue = re.sub('\\s+$','',dialogue)\n",
    "                    dataRaw += prevDialogue+'\\t'+dialogue+'\\n'\n",
    "                    inputs.append(prevDialogue)\n",
    "                    outputs.append(dialogue)\n",
    "                dataF.append([preChar.upper(),dialogue])\n",
    "                prevDialogue = re.sub('\\((.*?)\\)','',dialogue)\n",
    "                prevDialogue = re.sub(\"[’']\",\"\",prevDialogue)\n",
    "                prevDialogue = re.sub('^\\s+','',prevDialogue)\n",
    "                prevDialogue = re.sub('\\s+$','',prevDialogue)\n",
    "                dialogue=''\n",
    "\n",
    "            dialogue += re.sub('^[a-zA-Z]+:','',line)\n",
    "            preChar = charachter\n",
    "    return dataRaw, inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction list of episode files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('transcripts_friends\\\\season_all\\\\'):\n",
    "    for file in filenames:\n",
    "        if '.csv' in file:\n",
    "            episodes.append(dirpath+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction inputs and outputs for a particular `person` from all eposodes collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well, okay, Mikes taking a shower, which by the way theres no law against. And then were gonna grab some food, so if you want...', 'Ooh... Dr. Geller!', 'You gotta hear this, its great... Its like free porn!']\n",
      "['... finally...', 'God, youre amazing... I didnt even have to ask you to call me that.', 'Weh...*sigh*']\n",
      "8617 8617\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "person = 'ROSS'\n",
    "for episode in episodes:\n",
    "#     print(episode)\n",
    "    with open(episode,encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "        _, inp, out = readFile(lines, person)\n",
    "        inputs+=inp\n",
    "        outputs+=out\n",
    "print(inputs[0:3])\n",
    "print(outputs[0:3])\n",
    "print(len(inputs),len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting into train and test and saving collected input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestSplit = 0.8\n",
    "pickle.dump(inputs[:int(len(inputs)*trainTestSplit)], \n",
    "            open('data\\\\{}Data\\\\{}InputTrain.pkl'.format(person.lower(),person.lower()), 'wb'))\n",
    "pickle.dump(inputs[int(len(inputs)*trainTestSplit):], \n",
    "            open('data\\\\{}Data\\\\{}InputTest.pkl'.format(person.lower(),person.lower()), 'wb'))\n",
    "pickle.dump(outputs[:int(len(inputs)*trainTestSplit)], \n",
    "            open('data\\\\{}Data\\\\{}OutputTrain.pkl'.format(person.lower(),person.lower()), 'wb'))\n",
    "pickle.dump(outputs[int(len(inputs)*trainTestSplit):], \n",
    "            open('data\\\\{}Data\\\\{}OutputTest.pkl'.format(person.lower(),person.lower()), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
