{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'joey.npy'\n",
    "if '.npy' in data_path:\n",
    "    lines = str(np.load(data_path)).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lines = list()\n",
    "target_lines = list()\n",
    "for line in lines[0:500]:\n",
    "    if len(line):\n",
    "        inp,target = line.split('\\t')\n",
    "        input_lines.append(inp)\n",
    "        target_lines.append('<BOS> '+ target + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "with codecs.open(\"encoder_inputs.txt\", \"rb\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    encoder_text = []\n",
    "    for line in lines:\n",
    "        data = line.split(\"\\n\")[0]\n",
    "        encoder_text.append(data)\n",
    "with codecs.open(\"decoder_inputs.txt\", \"rb\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    decoder_text = []\n",
    "    for line in lines:\n",
    "        data = line.split(\"\\n\")[0]\n",
    "        decoder_text.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "encoder_text = encoder_text[:num_samples]\n",
    "decoder_text = decoder_text[:num_samples]\n",
    "full_text = encoder_text + decoder_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.text import Tokenizer\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(full_text)\n",
    "# word_index = tokenizer.word_index\n",
    "\n",
    "# encoder_sequences = tokenizer.texts_to_sequences(encoder_text)\n",
    "# decoder_sequences = tokenizer.texts_to_sequences(decoder_text)\n",
    "# decoder_output_data = np.zeros((num_samples, decoder_input_data.shape[1], len(word2index)), dtype=\"float32\")\n",
    "# for i, seqs in enumerate(decoder_input_data[0:498]):\n",
    "#     for j, seq in enumerate(seqs):\n",
    "#         if j > 0:\n",
    "#             decoder_output_data[i][j][seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {word:index+1 for index,(word,freq) in enumerate(Counter(re.sub('\\s+',' ',' '.join(full_text)).split()).items())}\n",
    "word2index['<UnKnown_Token>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {}\n",
    "for k, v in word2index.items():\n",
    "    index2word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sequences = []\n",
    "for sent in encoder_text:\n",
    "    encoder_sequences.append([word2index[word] for word in sent.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_sequences = []\n",
    "for sent in decoder_text:\n",
    "    decoder_sequences.append([word2index[word] for word in sent.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = max([len(i) for i in decoder_sequences])\n",
    "decoder_output_data = []\n",
    "for sents in decoder_sequences[0:10]:\n",
    "    sents = sents[1:]\n",
    "    oneHot = [[0 for i in range(len(word2index))] for j in range(MAX)]\n",
    "#     oneHot = np.zeros((MAX,len(word2index)))\n",
    "    for idx,word in enumerate(sents):\n",
    "        oneHot[idx][word] = 1.\n",
    "    decoder_output_data.append(oneHot)\n",
    "decoder_output_data = np.array(decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input_data = pad_sequences(encoder_sequences, dtype='int32', padding='post', truncating='post')\n",
    "decoder_input_data = pad_sequences(decoder_sequences, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that i am used to\n",
      "[40, 6, 18, 41, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "<BOS> yeah but these guys have never seen a horse  they just jack off to clint eastwood <EOS>\n",
      "[1280, 27, 112, 497, 141, 51, 187, 660, 10, 1289, 501, 147, 1290, 643, 20, 1291, 1292, 1281, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[27], [112], [497], [141], [51], [187], [660], [10], [1289], [501], [147], [1290], [643], [20], [1291], [1292], [1281], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[['yeah'], ['but'], ['these'], ['guys'], ['have'], ['never'], ['seen'], ['a'], ['horse'], ['they'], ['just'], ['jack'], ['off'], ['to'], ['clint'], ['eastwood'], ['<EOS>'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "sent = 9\n",
    "print(encoder_text[sent])\n",
    "print([i for i in encoder_input_data[sent]])\n",
    "# print([index2word[i] for i in encoder_input_data[sent]])\n",
    "print()\n",
    "print(decoder_text[sent])\n",
    "print([i for i in decoder_input_data[sent]])\n",
    "# print([index2word[i] for i in decoder_input_data[sent]])\n",
    "print([[idx for idx,j in enumerate(i) if j==1] for i in decoder_output_data[sent]])\n",
    "print([[index2word[idx] for idx,j in enumerate(i) if j==1] for i in decoder_output_data[sent]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Loded!\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print(\"Glove Loded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_creater(50, word_index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "embed_layer = Embedding(input_dim=len(word2index)+1, output_dim=50, trainable=True,)\n",
    "embed_layer.build((None,))\n",
    "embed_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer.get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, ), dtype='int32',)\n",
    "encoder_embedding = embed_layer(encoder_inputs)\n",
    "encoder_LSTM = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "\n",
    "decoder_inputs = Input(shape=(None, ), dtype='int32',)\n",
    "decoder_embedding = embed_layer(decoder_inputs)\n",
    "decoder_LSTM = LSTM(50, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(len(word2index), activation='softmax'))\n",
    "outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "model.compile(optimizer='adam', loss ='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 0.7321 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243ea78e630>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data[0:10], decoder_input_data[0:10]], \n",
    "                     decoder_output_data[0:10], \n",
    "                     epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = model.layers[4](model.layers[2](model.inputs[-1]), initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = model.layers[-1](decoder_outputs2)\n",
    "decoder_model = Model([model.inputs[-1]] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, state_h, state_c = model.layers[3](model.layers[2](model.inputs[0]))\n",
    "encoder_model = Model(model.inputs[0], [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'do', 'you', 'get', 'your', 'hair', 'to', 'look', 'like', 'that']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = encoder_sequences[100]\n",
    "[index2word[i] for i in input_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input as state vectors.\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "# Generate empty target sequence of length 1.\n",
    "target_seq = np.zeros((1,1))\n",
    "# Populate the first character of target sequence with the start character.\n",
    "target_seq[0, 0] = word2index['<BOS>']\n",
    "\n",
    "# Sampling loop for a batch of sequences\n",
    "# (to simplify, here we assume a batch of size 1).\n",
    "stop_condition = False\n",
    "decoded_sentence = ''\n",
    "while not stop_condition:\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # Sample a token\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = index2word[sampled_token_index]\n",
    "    decoded_sentence += ' '+sampled_char\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop character.\n",
    "    if (sampled_char == '<EOS>' or\n",
    "       len(decoded_sentence) > 52):\n",
    "        stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" proposition ' consuming ' whose freaky majesty whose\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Charachter:\n",
    "    def __init__(self,):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
